{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8fpR3adYDbYR"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem import PorterStemmer\n",
        "import json\n",
        "import nltk\n",
        "import unicodedata\n",
        "import re\n",
        "import string\n",
        "import joblib as joblib\n",
        "import pickle as pickle\n",
        "import dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asjRCCRrDhrt",
        "outputId": "9faafc5b-a9af-4e20-a10c-92dfe71151ad"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpunkt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# pip install unidecode\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munidecode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unidecode\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:777\u001b[0m, in \u001b[0;36mDownloader.download\u001b[1;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(s, prefix2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    769\u001b[0m     print_to(\n\u001b[0;32m    770\u001b[0m         textwrap\u001b[38;5;241m.\u001b[39mfill(\n\u001b[0;32m    771\u001b[0m             s,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    775\u001b[0m     )\n\u001b[1;32m--> 777\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincr_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_or_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Error messages\u001b[39;49;00m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mErrorMessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:629\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# Look up the requested collection or package.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_or_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_or_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m ErrorMessage(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo_or_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:603\u001b[0m, in \u001b[0;36mDownloader._info_or_id\u001b[1;34m(self, info_or_id)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_info_or_id\u001b[39m(\u001b[38;5;28mself\u001b[39m, info_or_id):\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(info_or_id, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_or_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m info_or_id\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:1009\u001b[0m, in \u001b[0;36mDownloader.info\u001b[1;34m(self, id)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mid\u001b[39m):\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the ``Package`` or ``Collection`` record for the\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m    given item.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packages:\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packages[\u001b[38;5;28mid\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:952\u001b[0m, in \u001b[0;36mDownloader._update_index\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url \u001b[38;5;241m=\u001b[39m url \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# Download the index file.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39minternals\u001b[38;5;241m.\u001b[39mElementWrapper(\n\u001b[1;32m--> 952\u001b[0m     \u001b[43mElementTree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[0;32m    953\u001b[0m )\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    956\u001b[0m \u001b[38;5;66;03m# Build a dictionary of packages.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\xml\\etree\\ElementTree.py:1218\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m \n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \n\u001b[0;32m   1216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m tree \u001b[38;5;241m=\u001b[39m ElementTree()\n\u001b[1;32m-> 1218\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\xml\\etree\\ElementTree.py:580\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    574\u001b[0m     parser \u001b[38;5;241m=\u001b[39m XMLParser()\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(parser, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parse_whole\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;66;03m# The default XMLParser, when it comes from an accelerator,\u001b[39;00m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;66;03m# can define an internal _parse_whole API for efficiency.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;66;03m# It can be used to parse the whole source without feeding\u001b[39;00m\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;66;03m# it with chunks.\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "# pip install unidecode\n",
        "from unidecode import unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnX2dMx-EZr8"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "data_train = pd.read_csv('../Data Splits/train_data_70_30.csv')\n",
        "data_val = pd.read_csv('../Data Splits/val_data_70_30.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = data_train['article']\n",
        "y_train = data_train['label']\n",
        "\n",
        "X_val = data_val['article']\n",
        "y_val = data_val['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FYd9AsIEjdB"
      },
      "outputs": [],
      "source": [
        "# Text preprocessing\n",
        "def remove_diacritics(text):\n",
        "    normalized = unicodedata.normalize(\"NFD\", text)\n",
        "    return \"\".join(c for c in normalized if unicodedata.category(c) != \"Mn\")\n",
        "\n",
        "def wordopt(text):\n",
        "    text = text.lower()\n",
        "    text = remove_diacritics(text)\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub(\"\\\\W\", \" \", text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "ps = PorterStemmer()\n",
        "with open('../stopwords-tl.json', 'r') as f:\n",
        "    stopwords = json.load(f)\n",
        "\n",
        "def preprocess(text):\n",
        "    text = wordopt(text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = [ps.stem(token) for token in tokens]\n",
        "    filtered = [stem for stem in stems if stem not in stopwords]\n",
        "    return filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS3kyG9DEmXh"
      },
      "outputs": [],
      "source": [
        "# Apply preprocess function to X_train\n",
        "X_train = X_train.apply(preprocess)\n",
        "\n",
        "# Apply preprocess function to X_val\n",
        "X_val = X_val.apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the preprocessed text into a list of strings\n",
        "X_train_processed = [' '.join(tokens) for tokens in X_train]\n",
        "X_val_processed = [' '.join(tokens) for tokens in X_val]\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_processed)\n",
        "\n",
        "# Transform the validation data using the same vectorizer\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val_processed)\n",
        "\n",
        "# Print the shape of the TF-IDF matrices (No of rows, No of columns)\n",
        "print(\"Shape of X_train_tfidf:\", X_train_tfidf.shape)\n",
        "print(\"Shape of X_val_tfidf:\", X_val_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the TfidfVectorizer using joblib\n",
        "joblib.dump(tfidf_vectorizer, '../ModelsV2/stackvectorizer_rf_new.joblib')\n",
        "\n",
        "with open('../ModelsV2/stackvectorizer_rf_new.pkl', 'wb') as f:\n",
        "    dill.dump(tfidf_vectorizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Keoy2gMGGQQ"
      },
      "outputs": [],
      "source": [
        "# Initializing base models\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "lr = LogisticRegression()\n",
        "rf = RandomForestClassifier()\n",
        "knn = KNeighborsClassifier()\n",
        "svm = SVC(probability=True)\n",
        "\n",
        "base_models = [mnb, lr, rf, knn, svm]\n",
        "base_names = ['MNB', 'LR', 'RF', 'KNN', 'SVM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvSlf1JYGLZj"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [1, 2, 3, 4, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Define the GridSearchCV\n",
        "rf_grid = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spJTs3UtHBAa",
        "outputId": "02714104-2de6-479a-a128-aa39fe45ccce"
      },
      "outputs": [],
      "source": [
        "rf_grid.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kt2XxWqaMzQG"
      },
      "outputs": [],
      "source": [
        "print(\"Best Hyperparameters: \", rf_grid.best_params_)\n",
        "print(\"Best Accuracy: {:.2f}%\".format(rf_grid.best_score_ * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zvxk_9ulNKst"
      },
      "outputs": [],
      "source": [
        "best_meta = rf_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZiwcWTUdtCl"
      },
      "outputs": [],
      "source": [
        "stack = StackingClassifier(estimators=list(zip(base_names, base_models)), final_estimator=best_meta, cv=5)\n",
        "stack.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d2vaplFxNavJ"
      },
      "outputs": [],
      "source": [
        "# Create an empty DataFrame for storing metrics\n",
        "metrics_df = pd.DataFrame(index=base_names + ['Stacking Model'], columns=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
        "\n",
        "\n",
        "# Evaluate base models\n",
        "for model, name in zip(base_models, base_names):\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_val_tfidf)\n",
        "    y_prob = model.predict_proba(X_val_tfidf)[:, 1]  # Probability for positive class for ROC curve\n",
        "\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    precision = precision_score(y_val, y_pred)\n",
        "    recall = recall_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "    print(f\"Metrics for {name}:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"AUC: {auc}\")\n",
        "    print(f\"Classification Report:\\n{classification_report(y_val, y_pred)}\")\n",
        "\n",
        "    # Store metrics in the DataFrame\n",
        "    metrics_df.loc[name] = [accuracy, precision, recall, f1, auc]\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_prob)\n",
        "    roc_auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "    # Plot ROC Curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {name}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RwULTlwbNsY9"
      },
      "outputs": [],
      "source": [
        "# Evaluate stacking model\n",
        "stack_y_pred = stack.predict(X_val_tfidf)\n",
        "stack_y_prob = stack.predict_proba(X_val_tfidf)[:, 1]  # Probability for positive class for ROC curve\n",
        "\n",
        "stack_accuracy = accuracy_score(y_val, stack_y_pred)\n",
        "stack_precision = precision_score(y_val, stack_y_pred)\n",
        "stack_recall = recall_score(y_val, stack_y_pred)\n",
        "stack_f1 = f1_score(y_val, stack_y_pred)\n",
        "stack_auc = roc_auc_score(y_val, stack_y_prob)\n",
        "\n",
        "print(\"Metrics for Stacking Model:\")\n",
        "print(f\"Accuracy: {stack_accuracy}\")\n",
        "print(f\"Precision: {stack_precision}\")\n",
        "print(f\"Recall: {stack_recall}\")\n",
        "print(f\"F1 Score: {stack_f1}\")\n",
        "print(f\"AUC: {stack_auc}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_val, stack_y_pred)}\")\n",
        "\n",
        "# ROC Curve for stacking model\n",
        "stack_fpr, stack_tpr, _ = roc_curve(y_val, stack_y_prob)\n",
        "stack_roc_auc = roc_auc_score(y_val, stack_y_prob)\n",
        "\n",
        "# Store stacking model metrics in the DataFrame\n",
        "metrics_df.loc['Stacking Model'] = [stack_accuracy, stack_precision, stack_recall, stack_f1, stack_auc]\n",
        "\n",
        "\n",
        "# Plot ROC Curve for stacking model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(stack_fpr, stack_tpr, label=f'Stacking Model (AUC = {stack_roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Stacking Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Display the comparison table\n",
        "print(\"Comparison of Models:\")\n",
        "print(metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model using joblib\n",
        "joblib.dump(stack, '../ModelsV2/stackmodel_rf_new.joblib')\n",
        "\n",
        "with open('../ModelsV2/stackmodel_rf_new.pkl', 'wb') as f:\n",
        "    dill.dump(stack, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
