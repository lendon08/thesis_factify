{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8fpR3adYDbYR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HnX2dMx-EZr8"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "data = pd.read_csv('fakenews.csv')\n",
        "\n",
        "# Shuffle the DataFrame while resetting the index\n",
        "data = data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.drop(columns=['label'])\n",
        "y = data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H1JN_jgx-Ism"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_data shape: (321, 2)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets (90% training, 10% testing) with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
        "\n",
        "# Merging for Test Data\n",
        "test_data = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Display the shapes of test set\n",
        "print(\"test_data shape:\", test_data.shape)\n",
        "\n",
        "test_data.to_csv('test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data_80_20 shape: (2308, 2)\n",
            "val_data_80_20 shape: (577, 2)\n"
          ]
        }
      ],
      "source": [
        "# Split the training data into training and validation sets (80% training, 20% validation)\n",
        "X_train_80, X_val_20, y_train_80, y_val_20 = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
        "\n",
        "# Merging for 80:20 Train - Val Data\n",
        "train_data_80_20 = pd.concat([X_train_80, y_train_80], axis=1)\n",
        "val_data_80_20 = pd.concat([X_val_20, y_val_20], axis=1)\n",
        "\n",
        "# Display the shapes of test and validation set\n",
        "print(\"train_data_80_20 shape:\", train_data_80_20.shape)\n",
        "print(\"val_data_80_20 shape:\", val_data_80_20.shape)\n",
        "\n",
        "# Exporting the merged datasets to CSV\n",
        "train_data_80_20.to_csv('train_data_80_20.csv', index=False)\n",
        "val_data_80_20.to_csv('val_data_80_20.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data_70_30 shape: (2019, 2)\n",
            "val_data_70_30 shape: (866, 2)\n"
          ]
        }
      ],
      "source": [
        "# Split the training data into training and validation sets (70% training, 30% validation)\n",
        "X_train_70, X_val_30, y_train_70, y_val_30 = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n",
        "\n",
        "# Merging for 80:20 Train - Val Data\n",
        "train_data_70_30 = pd.concat([X_train_70, y_train_70], axis=1)\n",
        "val_data_70_30 = pd.concat([X_val_30, y_val_30], axis=1)\n",
        "\n",
        "# Display the shapes of test and validation set\n",
        "print(\"train_data_70_30 shape:\", train_data_70_30.shape)\n",
        "print(\"val_data_70_30 shape:\", val_data_70_30.shape)\n",
        "\n",
        "# Exporting the merged datasets to CSV\n",
        "train_data_70_30.to_csv('train_data_70_30.csv', index=False)\n",
        "val_data_70_30.to_csv('val_data_70_30.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data_60_40 shape: (1731, 2)\n",
            "val_data_60_40 shape: (1154, 2)\n"
          ]
        }
      ],
      "source": [
        "# Split the training data into training and validation sets (60% training, 40% validation)\n",
        "X_train_60, X_val_40, y_train_60, y_val_40 = train_test_split(X_train, y_train, test_size=0.4, stratify=y_train, random_state=42)\n",
        "\n",
        "# Merging for 80:20 Train - Val Data\n",
        "train_data_60_40 = pd.concat([X_train_60, y_train_60], axis=1)\n",
        "val_data_60_40 = pd.concat([X_val_40, y_val_40], axis=1)\n",
        "\n",
        "# Display the shapes of test and validation set\n",
        "print(\"train_data_60_40 shape:\", train_data_60_40.shape)\n",
        "print(\"val_data_60_40 shape:\", val_data_60_40.shape)\n",
        "\n",
        "# Exporting the merged datasets to CSV\n",
        "train_data_60_40.to_csv('train_data_60_40.csv', index=False)\n",
        "val_data_60_40.to_csv('val_data_60_40.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
