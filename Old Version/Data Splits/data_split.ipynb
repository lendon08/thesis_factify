{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8fpR3adYDbYR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HnX2dMx-EZr8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows before removing duplicates: 3206\n",
            "Number of rows after removing duplicates: 3005\n"
          ]
        }
      ],
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "data = pd.read_csv('fakenews.csv')\n",
        "\n",
        "# Count the number of rows before removing duplicates\n",
        "num_rows_before = len(data)\n",
        "\n",
        "# Remove duplicates\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Count the number of rows after removing duplicates\n",
        "num_rows_after = len(data)\n",
        "\n",
        "print(\"Number of rows before removing duplicates:\", num_rows_before)\n",
        "print(\"Number of rows after removing duplicates:\", num_rows_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data['article']\n",
        "y = data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H1JN_jgx-Ism"
      },
      "outputs": [],
      "source": [
        "# Split the data into train (90%) and test (10%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
        "\n",
        "# Split the train set into train (70%) and validation (30%) sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 1892\n",
            "Validation set size: 812\n",
            "Test set size: 301\n"
          ]
        }
      ],
      "source": [
        "# Show the number of rows for train, test, and validation sets\n",
        "print(\"Train set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Test set size:\", len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set label counts:\n",
            "label\n",
            "1    950\n",
            "0    942\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test set label counts:\n",
            "label\n",
            "1    151\n",
            "0    150\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation set label counts:\n",
            "label\n",
            "1    408\n",
            "0    404\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count the occurrences of each class label in train, test, and validation sets\n",
        "train_label_counts = y_train.value_counts()\n",
        "test_label_counts = y_test.value_counts()\n",
        "val_label_counts = y_val.value_counts()\n",
        "\n",
        "print(\"\\nTrain set label counts:\")\n",
        "print(train_label_counts)\n",
        "print(\"\\nTest set label counts:\")\n",
        "print(test_label_counts)\n",
        "print(\"\\nValidation set label counts:\")\n",
        "print(val_label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_data shape: (301, 2)\n"
          ]
        }
      ],
      "source": [
        "# Merging for Test Data\n",
        "test_data = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Display the shapes of test set\n",
        "print(\"test_data shape:\", test_data.shape)\n",
        "\n",
        "test_data.to_csv('test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data_70_30 shape: (1892, 2)\n",
            "val_data_70_30 shape: (812, 2)\n"
          ]
        }
      ],
      "source": [
        "# Merging for 70:30 Train - Val Data\n",
        "train_data_70_30 = pd.concat([X_train, y_train], axis=1)\n",
        "val_data_70_30 = pd.concat([X_val, y_val], axis=1)\n",
        "\n",
        "# Display the shapes of test and validation set\n",
        "print(\"train_data_70_30 shape:\", train_data_70_30.shape)\n",
        "print(\"val_data_70_30 shape:\", val_data_70_30.shape)\n",
        "\n",
        "# Exporting the merged datasets to CSV\n",
        "train_data_70_30.to_csv('train_data_70_30.csv', index=False)\n",
        "val_data_70_30.to_csv('val_data_70_30.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
