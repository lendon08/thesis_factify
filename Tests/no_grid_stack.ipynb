{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "import json\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import string\n",
    "import joblib as joblib\n",
    "import pickle as pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# nltk.download('punkt')\n",
    "# pip install unidecode\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_train = pd.read_csv('../Dataset/train_data.csv')\n",
    "data_test = pd.read_csv('../Dataset/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['article']\n",
    "y_train = data_train['label']\n",
    "\n",
    "X_test = data_test['article']\n",
    "y_test = data_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\", \" \", text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "ps = PorterStemmer()\n",
    "with open('../Resources/stopwords-tl.json', 'r') as f:\n",
    "    stopwords = json.load(f)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = wordopt(text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = [ps.stem(token) for token in tokens]\n",
    "    filtered = [stem for stem in stems if stem not in stopwords]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocess function to X_train\n",
    "X_train = X_train.apply(preprocess)\n",
    "\n",
    "# Apply preprocess function to X_test\n",
    "X_test = X_test.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_tfidf: (2103, 27707)\n",
      "Shape of X_test_tfidf: (902, 27707)\n"
     ]
    }
   ],
   "source": [
    "# Convert the preprocessed text into a list of strings\n",
    "X_train_processed = [' '.join(tokens) for tokens in X_train]\n",
    "X_test_processed = [' '.join(tokens) for tokens in X_test]\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_processed)\n",
    "\n",
    "# Transform the validation data using the same vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_processed)\n",
    "\n",
    "# Print the shape of the TF-IDF matrices (No of rows, No of columns)\n",
    "print(\"Shape of X_train_tfidf:\", X_train_tfidf.shape)\n",
    "print(\"Shape of X_test_tfidf:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "base_models = [mnb, lr, rf, knn, svm]\n",
    "base_names = ['MNB', 'LR', 'RF', 'KNN', 'SVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_rf = joblib.load('../Models/Stack/stack_rf_5_final_953.joblib')\n",
    "stack_lr = joblib.load('../Models/Stack/stack_lr.joblib')\n",
    "stack_svm = joblib.load('../Models/Stack/stack_svm.joblib')\n",
    "stack_mlp = joblib.load('../Models/Stack/stack_mlp_2_958.joblib')\n",
    "\n",
    "models = [\n",
    "    (stack_lr, 'Logistic Regression'),\n",
    "    (stack_rf, 'Random Forest'),\n",
    "    (stack_svm, 'Support Vector Machine'),\n",
    "    (stack_mlp, 'Multi-layer Perceptron'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING BASE MODEL ACCURACY\n",
      "     Mean Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "MNB       0.831201   0.754853  0.983913  0.854194  0.974528\n",
      "LR        0.926298   0.964065  0.886377  0.923537  0.983689\n",
      "RF        0.927250   0.937265  0.910994  0.935669  0.979342\n",
      "KNN       0.857829   0.806495  0.943199  0.869470  0.942442\n",
      "SVM       0.935808   0.981206  0.889207  0.932936  0.988276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(columns=['Mean Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'])\n",
    "\n",
    "# Initialize lists to store ROC curve data\n",
    "plt.figure()\n",
    "\n",
    "print(\"TRAINING BASE MODEL ACCURACY\")\n",
    "for model, name in zip(base_models, base_names):\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    scores = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "    scores_precision = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='precision')\n",
    "    scores_recall = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='recall')\n",
    "    scores_f1 = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='f1')\n",
    "    scores_roc_auc = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='roc_auc') \n",
    "    mean_accuracy = scores.mean()\n",
    "    mean_scores_precision = scores_precision.mean()\n",
    "    mean_scores_recall = scores_recall.mean()\n",
    "    mean_scores_f1 = scores_f1.mean()\n",
    "    mean_scores_roc_auc = scores_roc_auc.mean()\n",
    "\n",
    "    metrics_df.loc[name] = [\n",
    "        mean_accuracy, \n",
    "        mean_scores_precision,\n",
    "        mean_scores_recall,\n",
    "        mean_scores_f1,\n",
    "        mean_scores_roc_auc,\n",
    "    ]\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in base_models:\n",
    "    model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING STACK MODEL ACCURACY\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This MultinomialNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAINING STACK MODEL ACCURACY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m stack \u001b[38;5;241m=\u001b[39m StackingClassifier(estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(base_names, base_models)), final_estimator\u001b[38;5;241m=\u001b[39mstack_lr)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mstack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(stack_lr, X_train_tfidf, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m scores_precision \u001b[38;5;241m=\u001b[39m cross_val_score(stack_lr, X_train_tfidf, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:669\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    668\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:283\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    277\u001b[0m     meth\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m ]\n\u001b[0;32m    282\u001b[0m X_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n\u001b[1;32m--> 283\u001b[0m \u001b[43m_fit_single_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_estimator_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:36\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m---> 36\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:669\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    668\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:210\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m all_estimators:\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 210\u001b[0m             \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mappend(estimator)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# predict_proba. They are exposed publicly.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MultinomialNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "basemodel_mnb = joblib.load('../Models/Base/basemodel_MNB.joblib')\n",
    "basemodel_lr = joblib.load('../Models/Base/basemodel_LR.joblib')\n",
    "basemodel_rf = joblib.load('../Models/Base/basemodel_RF.joblib')\n",
    "basemodel_knn = joblib.load('../Models/Base/basemodel_KNN.joblib')\n",
    "basemodel_svm = joblib.load('../Models/Base/basemodel_SVM.joblib')\n",
    "\n",
    "base_models_nogrid = [\n",
    "    basemodel_mnb, \n",
    "    basemodel_lr,\n",
    "    basemodel_rf,\n",
    "    basemodel_knn,\n",
    "    basemodel_svm\n",
    "]\n",
    "\n",
    "base_names_nogrid = ['MNB', 'LR', 'RF', 'KNN', 'SVM']\n",
    "\n",
    "print(\"TRAINING STACK MODEL ACCURACY\")\n",
    "\n",
    "stack = StackingClassifier(estimators=list(zip(base_names, base_models)), final_estimator=stack_lr)\n",
    "stack.fit(X_train_tfidf, y_train)\n",
    "\n",
    "scores = cross_val_score(stack_lr, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "scores_precision = cross_val_score(stack_lr, X_train_tfidf, y_train, cv=5, scoring='precision')\n",
    "scores_recall = cross_val_score(stack_lr, X_train_tfidf, y_train, cv=5, scoring='recall')\n",
    "scores_f1 = cross_val_score(stack_lr, X_train_tfidf, y_train, cv=5, scoring='f1')\n",
    "scores_roc_auc = cross_val_score(stack_lr, X_train_tfidf, y_train, cv=5, scoring='roc_auc') \n",
    "mean_accuracy = scores.mean()\n",
    "mean_scores_precision = scores_precision.mean()\n",
    "mean_scores_recall = scores_recall.mean()\n",
    "mean_scores_f1 = scores_f1.mean()\n",
    "mean_scores_roc_auc = scores_roc_auc.mean()\n",
    "\n",
    "metrics_df.loc[name] = [\n",
    "    mean_accuracy, \n",
    "    mean_scores_precision,\n",
    "    mean_scores_recall,\n",
    "    mean_scores_f1,\n",
    "    mean_scores_roc_auc,\n",
    "]\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAINING STACK MODEL ACCURACY\")\n",
    "for model, name in models:\n",
    "    stack_rf = StackingClassifier(estimators=list(zip(base_names, base_models)), final_estimator=stack_rf, cv='prefit')\n",
    "    stack_rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    scores = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "    scores_precision = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='precision')\n",
    "    scores_recall = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='recall')\n",
    "    scores_f1 = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='f1')\n",
    "    scores_roc_auc = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='roc_auc') \n",
    "    mean_accuracy = scores.mean()\n",
    "    mean_scores_precision = scores_precision.mean()\n",
    "    mean_scores_recall = scores_recall.mean()\n",
    "    mean_scores_f1 = scores_f1.mean()\n",
    "    mean_scores_roc_auc = scores_roc_auc.mean()\n",
    "\n",
    "    metrics_df.loc[name] = [\n",
    "        mean_accuracy, \n",
    "        mean_scores_precision,\n",
    "        mean_scores_recall,\n",
    "        mean_scores_f1,\n",
    "        mean_scores_roc_auc,\n",
    "    ]\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
